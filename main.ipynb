{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "genes =  [\n",
    "    \"C6orf150\",\n",
    "    \"CCL5\",\n",
    "    \"CXCL10\",\n",
    "    \"TMEM173\",\n",
    "    \"CXCL9\",\n",
    "    \"CXCL11\",\n",
    "    \"NFKB1\",\n",
    "    \"IKBKE\",\n",
    "    \"IRF3\",\n",
    "    \"TREX1\",\n",
    "    \"ATM\",\n",
    "    \"IL6\",\n",
    "    \"IL8\"\n",
    "  ]\n",
    "\n",
    "\n",
    "\n",
    "USERNAME = 'borna-personal'\n",
    "PROJECT = 'GENIE-Nextflow-v2'\n",
    "\n",
    "BASE_PATH = 'adj-mtrix'\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{USERNAME}/{PROJECT}\")\n",
    "\n",
    "if os.path.exists(f'{BASE_PATH}'):\n",
    "    shutil.rmtree(f'{BASE_PATH}')\n",
    "os.mkdir(f'{BASE_PATH}')\n",
    "\n",
    "for run in runs:\n",
    "    cancer = run.config.get('cancers')\n",
    "    adj_matrix = run.summary.get('adjacency_matrix')\n",
    "    target = run.config.get('variable')\n",
    "\n",
    "    if not os.path.exists(f'{BASE_PATH}/{cancer}'):\n",
    "        os.mkdir(f'{BASE_PATH}/{cancer}')\n",
    "    \n",
    "\n",
    "    with open(f'{BASE_PATH}/{cancer}/{target}-adj-matrix.obj', 'wb') as fh:\n",
    "        pickle.dump(adj_matrix, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import DataListLoader\n",
    "\n",
    "from scripts.genie_utils import load_config\n",
    "from scripts.gcn import GraphConvolutionalNetwork, GCNModelTrainer\n",
    "\n",
    "LR = 0.0001\n",
    "WD = 1e-1\n",
    "HIDDEN_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open('dumps/BLCA_dataset.obj', 'rb') as fh:\n",
    "        dataset = pickle.load(fh)\n",
    "\n",
    "    with open('adj-matrix/BLCA/DSS-adj-matrix.obj', 'rb') as fh:\n",
    "        adj_matrix = pickle.load(fh)\n",
    "\n",
    "    config = load_config('scripts/genie_config.json')\n",
    "    list_of_genes = config['genes']\n",
    "    NODES = dataset[0].x.shape[-1]\n",
    "    ADJ_MATRIX_SHAPE = (NODES, NODES)\n",
    "    NUM_CLASSES = dataset[0].y.shape[-1]\n",
    "\n",
    "    split_idx = round(0.75 * len(dataset))\n",
    "    train_dataset = dataset[:split_idx]\n",
    "    test_dataset = dataset[split_idx:]\n",
    "\n",
    "    train_loader = DataListLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataListLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    def epoch_finished(epoch, tr_f1, tr_loss, f1, loss):\n",
    "        print({\"epoch\": epoch, \"train_f1\": tr_f1, \"train_loss\": tr_loss, \"f1\": f1, \"loss\": loss})\n",
    "        pass\n",
    "\n",
    "    model = GraphConvolutionalNetwork(num_node_features=1, num_nodes=NODES, num_classes=NUM_CLASSES, hidden_channels=HIDDEN_SIZE,\n",
    "                                      adj_matrix=adj_matrix)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "    trainer = GCNModelTrainer(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                              num_classes=NUM_CLASSES, epochs=EPOCHS)\n",
    "    print('training started')\n",
    "    final_f1 = trainer.train(train_loader=train_loader, test_loader=test_loader, on_epoch_finished=epoch_finished)\n",
    "    print('\\nfinished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "runs = wandb.Api().runs('borna-personal/GENIE-Nextflow-IG-Reruns')\n",
    "df = runs[0].history()[['attributions', 'class']].iloc[-2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSS_1 : [0.008060641231686096, 5.964795482662625e-05, 0.03289338381167286, 0.01583801060180481, 0.04500872355916577, 0.06437164859009172, 0.01217993710528911, 0.008160756662641353, 0.002002890985192178, 0.0062118510120335695, 0.0001485172278512529, 0.0065553948709312845, 0.013543413918366352]\n",
      "DSS_0 : [0.005900392706390255, 4.280109699305358e-05, 0.024195390482158925, 0.011129337242501028, 0.0320670176473587, 0.04726706123090146, 0.009406753726771435, 0.006475167829103952, 0.001719187297999782, 0.004879879928410557, 0.00011139768564012367, 0.004528087286163789, 0.009994458465569818]\n"
     ]
    }
   ],
   "source": [
    "for row in df.values:\n",
    "    print(row[1], ':', row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "outputs: dict = {\n",
    "    'STAGE': ['early', 'late'],\n",
    "    'DSS': ['DSS_1', 'DSS_0'],\n",
    "    'OS': ['OS_1', 'OS_0'],\n",
    "    'GENDER': ['gender_female', 'gender_male']\n",
    "}\n",
    "\n",
    "target = 'DSS'\n",
    "cancer = 'LUSC'\n",
    "\n",
    "df = pd.read_csv(f'dumps/{cancer}_dataset_dump.csv')\n",
    "\n",
    "def draw_graph(attrs):\n",
    "    cmap = plt.cm.RdPu\n",
    "    colors = [cmap(val) for val in attrs]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    G = nx.from_numpy_array(np.array(adj_matrix))\n",
    "    labels = {i: gene for i, gene in enumerate(config['genes'])}\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    nx.draw(G, pos, labels=labels, with_labels=True, node_color=colors, node_size=500, font_size=12)\n",
    "\n",
    "\n",
    "feature_importance = np.array([])\n",
    "\n",
    "for class_index in range(NUM_CLASSES):\n",
    "\n",
    "    temp_dataset = []\n",
    "    _class = outputs[target][class_index]\n",
    "    for _, row in df[df[_class] == 1].iterrows():\n",
    "        gene_data = torch.tensor(row[:num_genes].values, dtype=torch.float).view(1, -1)\n",
    "        label = torch.tensor(row[num_genes:].values, dtype=torch.float).view(-1, len(row[num_genes:]))\n",
    "        temp_dataset.append(Data(x=gene_data, y=label))\n",
    "\n",
    "    data_loader = DataListLoader(temp_dataset, batch_size=64)\n",
    "\n",
    "    total_attributions = []\n",
    "    for i, sample in tqdm(enumerate(temp_dataset), total=len(temp_dataset), position=0, leave=False):\n",
    "        integrated_gradients = IntegratedGradients(model)\n",
    "\n",
    "        # inputs = sample.x.unsqueeze(-1)\n",
    "\n",
    "        # X = torch.stack(tuple(data.x for data in batch)).reshape(shape=(len(batch), num_genes)).unsqueeze(-1)\n",
    "        # print(sample.y.unsqueeze(-1))\n",
    "        attributions = integrated_gradients.attribute(inputs=sample.x.unsqueeze(-1), target=class_index)\n",
    "        attributions = attributions.squeeze().numpy()\n",
    "        total_attributions.append(np.abs(attributions))\n",
    "\n",
    "    feature_importance = np.mean(total_attributions, axis=0)\n",
    "      \n",
    "    \n",
    "    print(outputs[target][class_index], ':', feature_importance)\n",
    "    draw_graph([math.log10(val + 1) for val in feature_importance])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
